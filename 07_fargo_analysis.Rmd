---
title: "SFPA Player Ratings, v.1"
author: "Skip Perry"
date: "March 2019"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)

latest_fargo_date <- 
  list.files("other_data", pattern = "fargo") %>% 
  str_extract("\\d+-\\d+-\\d+") %>% 
  max()

fargo_path <-
  str_c("other_data/fargo_", latest_fargo_date, ".Rdata")

fargo_df <- 
  fargo_path %>% 
  read_rds()

latest_results_date <- 
  list.files("match_data", pattern = "results_no_forfeits") %>% 
  str_extract("\\d+-\\d+-\\d+") %>% 
  max()

results_no_forfeits_path <-
  str_c("match_data/results_no_forfeits_", latest_results_date, ".Rdata")

results_no_forfeits <- 
  results_no_forfeits_path %>% 
  read_rds()

results_19_no_forfeits <- 
  results_no_forfeits %>% 
  filter(season == "Spring 2019")
```

```{r, echo=FALSE}
count_games <- function(player_of_interest, results_df) {
  results_df %>% 
    filter(away == player_of_interest | home == player_of_interest) %>% 
    count() %>% 
    transmute(player = player_of_interest, games_in_system = n) %>% 
    pull()
}

games_in_system <- 
  bind_rows(
    results_no_forfeits %>% select(player = home),
    results_no_forfeits %>% select(player = away)
  ) %>% 
  distinct() %>% 
  arrange(player) %>% 
  mutate(games_in_system = 0)

for (i in 1:nrow(games_in_system)) {
  games_in_system$games_in_system[i] <- 
    count_games(games_in_system$player[i], results_no_forfeits)
}
```

```{r, echo=FALSE}
team_names_by_player <- 
  bind_rows(
    results_19_no_forfeits %>% select(player = home, team = home_team),
    results_19_no_forfeits %>% select(player = away, team = away_team)
  ) %>% 
    distinct() %>% 
    arrange(player, team)

ratings_for_printing <- 
  fargo_df %>% 
  arrange(desc(rating)) %>% 
  mutate(rank = row_number()) %>% 
  left_join(team_names_by_player, by = "player") %>% 
  left_join(games_in_system, by = "player") %>% 
  transmute(
    rank, 
    player, 
    current_team = replace_na(team, "--"), 
    rating = round(rating),
    games_in_system
  )
```

### The Math Behind the Ratings 

These ratings are based on the Bradley-Terry model, which since the 1950s has been one of the standard methods of assessing the skill of competitors who are repeatedly paired against one another. Considering two players $i$ and $j$ with ratings $\pi_i$ and $\pi_j$, this framework assumes player $i$ has the following probability of defeating player $j$:

$$\text{P[Player } i \text{ defeats player } j] = p_{i > j} = \frac{\pi_i}{\pi_i + \pi_j}$$

A common place to start when trying to estimate parameters like these is maximum likelihood estimation. The general setup is that each game's outcome has some probability of occurring, modeled as $\frac{\pi_i}{\pi_i + \pi_j}$. If we assume that the data points are independent and identically distributed, the likelihood of all observed games is simply the probability of all the games multiplied together. The maximum likelihood estimate, or MLE, is the collection of player ratings $\pi_1, ..., \pi_n$ for all $n$ players in the league that maximizes this likelihood function.

While there is no general analytical solution for the MLE in this case, iterative methods can be used to find a result. Letting $\pi_i$ be player $i$'s rating, $w_i$ the number of times player $i$ won a game, $n_{ij}$ the number of games played between players $i$ and $j$, and $(t)$ labeling the result at the $t^{th}$ iteration, we can use the following update formula:

$$\pi_i^{(t)} = \frac{w_i}{\sum_{j \neq i} \frac{n_{ij}}{\pi_i^{(t-1)} + \pi_j^{(t-1)}}}$$

Or, in a format that may be easier to understand: 

$$\pi_i^{new} = \frac{\text{# of total wins by player } i}{\sum_{\text{All games played by } i} \frac{\text{# of games between } i, j}{\pi_i^{current} + \pi_j^{current}}}$$

This adaptation of the expectation-maximization (EM) algorithm loops through each player, updating their rating using the latest estimates of all their opponents' ratings. (A little experimentation with Google Calculator or Excel will demonstrate how this formula gives players more credit for beating higher-ranked opponents.) Eventually, each update will have such a small effect on the vector of player ratings $\pi$ that we can stop the process. 

Maximum likelihood estimation is the single most widely used method of parameter estimation, but it is far from perfect. While convergence is guaranteed under certain conditions, one of those conditions deals with having a sufficient number of connections in the data, such as you might find in a series of round-robin games played between all teams in a league ([see Assumption 3 here](http://personal.psu.edu/drh20/papers/bt.pdf)). Additionally, the MLE can converge toward the boundary of a parameter space when dealing with extreme data, which in this case would mean a rating of 0 for a winless player and a rating of infinity for an undefeated one. This presents a clear problem when plugging ratings into the formula $\frac{\pi_i}{\pi_i + \pi_j}$. The SFPA league data set faces both of these issues - sparse data with many members playing only a handful of games against a limited subset of opponents, and some examples of players with no wins at all.

Bayesian methods allow us to avoid these problems.  Instead of finding an MLE after taking undesirable steps like omitting winless players or including only results from players with a minimum number of games, we calculate the maximum a priori (MAP) estimate of **$\pi$** by setting a $\Gamma(a, b)$ prior on $\pi$, where $\Gamma$ is a gamma probability distribution with parameters $a$ and $b$. This prior is conjugate to the complete data likelihood function and results in the following update formula:

$$\pi_i^{(t)} = \frac{a - 1 + w_i}{b + \sum_{j \neq i} \frac{n_{ij}}{\pi_i^{(t-1)} + \pi_j^{(t-1)}}}$$

Like the MLE, MAP estimation provides a point estimate, though in this case it is the mode of a posterior distribution rather than the maximization of a likelihood function. (Note that for $a = 1$ and $b = 0$, the MAP and maximum likelihood estimates are equivalent; see [here](http://www.stats.ox.ac.uk/~doucet/caron_doucet_bayesianbradleyterry.pdf) for more information.) 

Under this setup, as in many Bayesian applications, the choice of prior has a major impact on the model. When $a = 1$, we simply have the MLE; as the value of $a$ increases, the impact of actual game results decreases as the numerator and denominator in the update formula become dominated by the constant $a-1$ and $b$ terms. Hyperparameter tuning for $a$ resulted in an optimal choice of 2.75 - a weakly informative prior. 

The scale of these ratings is arbitrary; any set of ratings can be multiplied by some positive constant and result in the same probability $p_{i>j}$ for all $i$ and $j$. As a result, in the MLE context, we would need to peg a player rating $\pi_i$ to a particular value, or set up an additional constraint such as $1 / n * \sum_{i=1}^{n} \pi_i = 1000$, in order to arrive at a unique solution. In the MAP formulation, we can make the model identifiable by setting $b = (a - 1) / 500$ and ensure a mean player rating of roughly 500 in the process.

Other considerations included:

* Home-table advantage: In the past three seasons, about 52% of games were won by the home team, a small but significant edge to the home player. There also exists a simple way to incorporate this factor into the ratings, letting $p_{i>j} = \frac{\theta \pi_i}{\theta \pi_i + \pi_j}$ where $\theta > 1$ is the home-table advantage (or $\theta < 1$ if it's a disadvantage). Unfortunately, this is a noisy input: due to scheduling conflicts and bar remodeling, teams often play "home" games at other bars; most week 1 games are home games for both teams; and playoff games represent an uneven playing field since higher-seeded teams play at home while lower-seeded teams play on the road, among other factors. After quite a bit of experimentation in this area failed to improve model performance, I omitted the home-table advantage from the rating system.

* Time decay: In pool, a player's skill level can sometimes change over time. One extreme would be to assume that these changes are the result of random noise and place equal weight on every game in a player's match history; another would be to use a subset of a player's most recent games, on the assumption that those games most accurately reflect their skill. The middle ground solution used here is a sliding scale where older matches contribute less to a player's rating than newer ones. Matches are given a weighting factor between 0 and 1 based on a half-life of 1500 days from the date of a player's latest game. (As an example, for the latest March 2019 ratings, matches played in January 2018 contribute about 80% of the value of a match played in the current month.) Since parameter tuning on the number of days to half-life showed little impact on model results, this number was chosen arbitrarily. The end result is a rating system that is responsive to change but results in fewer wild temporary swings, especially for players with more established ratings. 

* Robustness: In order to prevent new players with ratings based on a small amount of data from having an outsize impact on the ratings of more established players, games against newly-joined league members are down-weighted until those players have competed in a certain number of games. As with the time decay, experimentation with different reasonable values of this parameter showed a negligible impact on model performance. The number 15 was chosen based on an exploratory analysis of when players' ratings begin to converge to a relative steady state.

* Scaling: Due to the wide variation in playing ability across the league, values for $\pi$ are highly skewed. Using a logarithmic transform...

### Questions and Answers 

What do the ratings mean? 

* The first meaningful number here is 500, which has been set as the global league average. Otherwise, ratings are primarily useful in comparison to each other. The second meaningful number is a rating difference of 100, which denotes a...  to calculate individual match probabilities: the probability of player A beating player B in a single game is equal to $1 / (1 + e^{(R_B - R_A) / 150})$. 

How and why does my rating go up or down?

* Your rating will go up when you perform better than the current ratings predict, and it will go down if you perform worse than the current ratings predict. Your rating will also change based on changes in your opponents' ratings. Let's assume you have a 6-3 record against some previous opponent. If that opponent has a few great nights and his or her rating increases, you will earn more points for having done well against that person. (The converse is true if your previous opponent's rating decreases.)

How much do ratings change over time?

* Some players perform at a consistent level and show only minor changes over time. Other people have seen large shifts in their ratings, both positive and negative. Substantial changes in players' ratings are almost always due to changes in their own performance, rather than changes in the performance of their previous opponents. 

Do new league players have starter ratings?

* Not exactly. Players start out with a rating of 500, but from the very beginning their match results start to affect their ratings. Instead of holding a new player to an arbitrary starter rating for some arbitrary period of time, we allow the results to follow the data even if that data is noisy at first.

How many games are needed to indicate that a rating is trustworthy?

* This is not a simple question. We are in the process of generating confidence intervals (or, more accurately, Bayesian credible intervals) for ratings to give an idea of how sure we may be. Initial exploration suggests 15 games is the time period when the mean and median week-to-week rating changes hit 0 and the standard deviation approaches a relative plateau.

### Ratings as of April 2, 2019

```{r, echo=FALSE}
ratings_for_printing %>% 
  arrange(desc(rating)) %>% 
  knitr::kable()
```

```{r, echo=FALSE}
fargo_for_team_plots <- 
  ratings_for_printing %>% 
  filter(current_team != "--") %>% 
  group_by(current_team) %>% 
  arrange(current_team, desc(rating)) %>% 
  mutate(
    team_rank = row_number(),
    top4 = team_rank < 5
  ) %>% 
  ungroup() %>% 
  mutate(qtile = as.factor(ntile(rating, 6)))

fargo_for_team_plots %>% 
  group_by(current_team) %>% 
  mutate(team_rating = exp(mean(log(rating)))) %>% 
  ggplot(aes(x = reorder(current_team, team_rating))) +
  geom_point(aes(y = team_rating), color = "gray50", size = 1.7, alpha = 0.5) +
  geom_vline(xintercept = 18.5, color = "green", alpha = 0.2, size = 1) +
  geom_point(aes(y = rating, color = qtile), alpha = 0.5) +
  coord_flip() +
  theme(
    axis.title = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) +
  labs(
    title = "Ratings by Team and Player (Full Team)",
    color = "Sextile"
  )

fargo_for_team_plots %>% 
  filter(top4 == TRUE) %>% 
  group_by(current_team) %>% 
  mutate(team_rating = exp(mean(log(rating)))) %>% 
  ggplot(aes(x = reorder(current_team, team_rating))) +
  geom_point(aes(y = team_rating), color = "gray50", size = 1.7, alpha = 0.5) +
  geom_vline(xintercept = 18.5, color = "green", alpha = 0.2, size = 1) +
  geom_point(aes(y = rating, color = qtile), alpha = 0.5) +
  coord_flip() +
  theme(
    axis.title = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) +
  labs(
    title = "Ratings by Team and Player (Top 4 Only)",
    color = "Sextile"
  )
```

